{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6116858",
   "metadata": {},
   "source": [
    "## Variable length sequence LSTM full script\n",
    "\n",
    "In this script, the whole process of loading data, training and testing the LSTM is written.\n",
    "The script is as generalized as it can get, since the variables of the model change based on the underlying dataset.\n",
    "This has been done to allow for the addition of new actions and data without having to change the code.\n",
    "Since it is a variable length sequence LSTM, ragged tensors are used.\n",
    "The predicting logic is a fixed length LSTM with 8 frame length. Being it real-time, it is not possible to predict variable length sequence, since one does not now when the sequence is completed. A challenge will be finding the sweet spot in terms of sequence length (for now it is 8 frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9ed5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing needed libraries\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dc03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the mediapipe model\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "#defining a few functions to detect, draw and extract keypoints\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    #this function takes in the image and the model and returns the prediction results\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results, drawing_spec_circle, drawing_spec_line):\n",
    "    #this function takes in the image and results and draws mediapipe landmarks on the picture\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, landmark_drawing_spec=drawing_spec_circle, connection_drawing_spec=drawing_spec_line)\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, landmark_drawing_spec=drawing_spec_circle, connection_drawing_spec=drawing_spec_line)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, landmark_drawing_spec=drawing_spec_circle, connection_drawing_spec=drawing_spec_line)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, landmark_drawing_spec=drawing_spec_circle, connection_drawing_spec=drawing_spec_line)\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    #this function takes in the prediction results and returns the array with the extracted keypoints to be saved\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "def visualize_probabilities(res, actions, input_frame, colors):\n",
    "    #this function takes in the action probabilities and actions, and draws the coloured probability rectangles on the picture\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*200), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a0e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the action categories and paths\n",
    "\n",
    "actions = []\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), \"DATA\")\n",
    "\n",
    "for action in os.listdir(DATA_PATH):\n",
    "    actions.append(action)\n",
    "    \n",
    "actions = np.array(actions)\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "\n",
    "labels, temp_points = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7924865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a temporary solution to the initializing ragged tensors problem is to initialize with a standard value and then deleting it at\n",
    "#the end. I didn't find any better solution since documentation on ragged tensors is not so clean\n",
    "temporary_ragged = tf.ragged.constant([[[3, 1, 4, 1], [5, 9, 2], [6], []]], tf.double)\n",
    "\n",
    "#for every action, loops and loads data for training\n",
    "for action in actions: \n",
    "    for num_sequence in os.listdir(os.path.join(DATA_PATH, action)):\n",
    "        temp_points = []\n",
    "        for point in os.listdir(os.path.join(DATA_PATH, action, num_sequence)):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, num_sequence, point), allow_pickle = True)\n",
    "            temp_points.append(res)       \n",
    "            \n",
    "        temporary_ragged = tf.concat([temporary_ragged, tf.expand_dims(np.array(temp_points), axis = 0)], axis = 0)\n",
    "        labels.append(label_map[action])\n",
    "\n",
    "#skips the first tensor, that is the one we used to intialize the variable\n",
    "dataset = temporary_ragged[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6246a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 7)\n"
     ]
    }
   ],
   "source": [
    "#preparing train and test sets (not really the cleanest way, ragged tensors don't seem too friendly to handle).\n",
    "#In the future I should add data augmentation as well, but it will probably be not clean to do that with ragged tensors\n",
    "\n",
    "y = to_categorical(labels).astype(int)\n",
    "train_ind = int(dataset.shape[0]*0.9)\n",
    "X_train = dataset[:train_ind]\n",
    "X_test = dataset[train_ind:]\n",
    "y_train = y[:train_ind]\n",
    "y_test = y[train_ind:]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da640329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the Keras model. Different models have been tested, for now with the dataset we have this has performed the best\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=[None, 1662], ragged=True),\n",
    "    tf.keras.layers.LSTM(64, activation = 'tanh', dropout=0.2, return_sequences = True),\n",
    "    tf.keras.layers.LSTM(128, activation = 'tanh', dropout=0.2, return_sequences = True),\n",
    "    tf.keras.layers.LSTM(64, activation = 'tanh', dropout=0.2),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(actions), activation = 'softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1d162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining compiler and callback to stop training and 97% accuracy\n",
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "ACCURACY_THRESHOLD = 0.97\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('categorical_accuracy') > ACCURACY_THRESHOLD):   \n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd3b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "28/28 [==============================] - 12s 257ms/step - loss: 1.8557 - categorical_accuracy: 0.2191\n",
      "Epoch 2/4000\n",
      "28/28 [==============================] - 7s 244ms/step - loss: 1.7962 - categorical_accuracy: 0.2427\n",
      "Epoch 3/4000\n",
      "28/28 [==============================] - 7s 248ms/step - loss: 1.7041 - categorical_accuracy: 0.2596\n",
      "Epoch 4/4000\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 1.6711 - categorical_accuracy: 0.2843\n",
      "Epoch 5/4000\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 1.6689 - categorical_accuracy: 0.2888\n",
      "Epoch 6/4000\n",
      "28/28 [==============================] - 8s 288ms/step - loss: 1.5830 - categorical_accuracy: 0.3146\n",
      "Epoch 7/4000\n",
      "28/28 [==============================] - 7s 260ms/step - loss: 1.5628 - categorical_accuracy: 0.3270\n",
      "Epoch 8/4000\n",
      "28/28 [==============================] - 8s 272ms/step - loss: 1.4651 - categorical_accuracy: 0.4022\n",
      "Epoch 9/4000\n",
      "28/28 [==============================] - 9s 323ms/step - loss: 1.4106 - categorical_accuracy: 0.4494\n",
      "Epoch 10/4000\n",
      "28/28 [==============================] - 7s 265ms/step - loss: 1.3590 - categorical_accuracy: 0.4247\n",
      "Epoch 11/4000\n",
      "28/28 [==============================] - 8s 305ms/step - loss: 1.4680 - categorical_accuracy: 0.3933\n",
      "Epoch 12/4000\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 1.4435 - categorical_accuracy: 0.4270\n",
      "Epoch 13/4000\n",
      "28/28 [==============================] - 8s 282ms/step - loss: 1.3547 - categorical_accuracy: 0.4416\n",
      "Epoch 14/4000\n",
      "28/28 [==============================] - 9s 307ms/step - loss: 1.3297 - categorical_accuracy: 0.4584\n",
      "Epoch 15/4000\n",
      "28/28 [==============================] - 9s 307ms/step - loss: 1.6786 - categorical_accuracy: 0.2966\n",
      "Epoch 16/4000\n",
      "28/28 [==============================] - 7s 262ms/step - loss: 1.5069 - categorical_accuracy: 0.3393\n",
      "Epoch 17/4000\n",
      "28/28 [==============================] - 8s 271ms/step - loss: 1.4551 - categorical_accuracy: 0.3708\n",
      "Epoch 18/4000\n",
      "28/28 [==============================] - 8s 290ms/step - loss: 1.4234 - categorical_accuracy: 0.3742\n",
      "Epoch 19/4000\n",
      "28/28 [==============================] - 11s 388ms/step - loss: 1.3310 - categorical_accuracy: 0.4382\n",
      "Epoch 20/4000\n",
      "28/28 [==============================] - 11s 380ms/step - loss: 1.2250 - categorical_accuracy: 0.4854\n",
      "Epoch 21/4000\n",
      "28/28 [==============================] - 10s 343ms/step - loss: 1.4605 - categorical_accuracy: 0.3809\n",
      "Epoch 22/4000\n",
      "28/28 [==============================] - 10s 352ms/step - loss: 1.2663 - categorical_accuracy: 0.4865\n",
      "Epoch 23/4000\n",
      "28/28 [==============================] - 10s 357ms/step - loss: 1.2127 - categorical_accuracy: 0.5191\n",
      "Epoch 24/4000\n",
      "28/28 [==============================] - 10s 355ms/step - loss: 1.1357 - categorical_accuracy: 0.5315\n",
      "Epoch 25/4000\n",
      "28/28 [==============================] - 10s 366ms/step - loss: 1.1591 - categorical_accuracy: 0.5202\n",
      "Epoch 26/4000\n",
      "28/28 [==============================] - 10s 367ms/step - loss: 1.3595 - categorical_accuracy: 0.4292\n",
      "Epoch 27/4000\n",
      "28/28 [==============================] - 10s 350ms/step - loss: 1.1919 - categorical_accuracy: 0.5011\n",
      "Epoch 28/4000\n",
      "28/28 [==============================] - 10s 354ms/step - loss: 1.1492 - categorical_accuracy: 0.5202\n",
      "Epoch 29/4000\n",
      "28/28 [==============================] - 10s 364ms/step - loss: 1.0771 - categorical_accuracy: 0.5292\n",
      "Epoch 30/4000\n",
      "28/28 [==============================] - 10s 359ms/step - loss: 1.0841 - categorical_accuracy: 0.5404\n",
      "Epoch 31/4000\n",
      "28/28 [==============================] - 10s 361ms/step - loss: 1.1770 - categorical_accuracy: 0.5090\n",
      "Epoch 32/4000\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 1.0294 - categorical_accuracy: 0.5517\n",
      "Epoch 33/4000\n",
      "28/28 [==============================] - 10s 353ms/step - loss: 1.0387 - categorical_accuracy: 0.5449\n",
      "Epoch 34/4000\n",
      "28/28 [==============================] - 10s 323ms/step - loss: 1.0237 - categorical_accuracy: 0.5708\n",
      "Epoch 35/4000\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 1.0298 - categorical_accuracy: 0.5461\n",
      "Epoch 36/4000\n",
      "28/28 [==============================] - 10s 358ms/step - loss: 0.9801 - categorical_accuracy: 0.5708\n",
      "Epoch 37/4000\n",
      "28/28 [==============================] - 10s 359ms/step - loss: 0.9904 - categorical_accuracy: 0.5719\n",
      "Epoch 38/4000\n",
      "28/28 [==============================] - 11s 384ms/step - loss: 0.9926 - categorical_accuracy: 0.5551\n",
      "Epoch 39/4000\n",
      "28/28 [==============================] - 10s 377ms/step - loss: 0.9992 - categorical_accuracy: 0.5708\n",
      "Epoch 40/4000\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.9899 - categorical_accuracy: 0.5753\n",
      "Epoch 41/4000\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.9361 - categorical_accuracy: 0.5787\n",
      "Epoch 42/4000\n",
      "28/28 [==============================] - 10s 343ms/step - loss: 0.9023 - categorical_accuracy: 0.5921\n",
      "Epoch 43/4000\n",
      "28/28 [==============================] - 9s 335ms/step - loss: 0.9447 - categorical_accuracy: 0.5910\n",
      "Epoch 44/4000\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.9395 - categorical_accuracy: 0.5820\n",
      "Epoch 45/4000\n",
      "28/28 [==============================] - 10s 352ms/step - loss: 1.1239 - categorical_accuracy: 0.5236\n",
      "Epoch 46/4000\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.9428 - categorical_accuracy: 0.5854\n",
      "Epoch 47/4000\n",
      "28/28 [==============================] - 10s 354ms/step - loss: 0.9023 - categorical_accuracy: 0.5955\n",
      "Epoch 48/4000\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.9320 - categorical_accuracy: 0.5899\n",
      "Epoch 49/4000\n",
      "28/28 [==============================] - 10s 343ms/step - loss: 0.9080 - categorical_accuracy: 0.5955\n",
      "Epoch 50/4000\n",
      "28/28 [==============================] - 10s 350ms/step - loss: 0.8710 - categorical_accuracy: 0.6258\n",
      "Epoch 51/4000\n",
      "28/28 [==============================] - 10s 352ms/step - loss: 0.8306 - categorical_accuracy: 0.6360\n",
      "Epoch 52/4000\n",
      "28/28 [==============================] - 10s 348ms/step - loss: 0.8216 - categorical_accuracy: 0.6449\n",
      "Epoch 53/4000\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.8333 - categorical_accuracy: 0.6685\n",
      "Epoch 54/4000\n",
      "28/28 [==============================] - 10s 359ms/step - loss: 0.9009 - categorical_accuracy: 0.6371\n",
      "Epoch 55/4000\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.9761 - categorical_accuracy: 0.5989\n",
      "Epoch 56/4000\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 0.8860 - categorical_accuracy: 0.6326\n",
      "Epoch 57/4000\n",
      "28/28 [==============================] - 10s 353ms/step - loss: 0.8480 - categorical_accuracy: 0.6787\n",
      "Epoch 58/4000\n",
      "28/28 [==============================] - 10s 372ms/step - loss: 0.8006 - categorical_accuracy: 0.6719\n",
      "Epoch 59/4000\n",
      "28/28 [==============================] - 10s 374ms/step - loss: 0.8231 - categorical_accuracy: 0.6865\n",
      "Epoch 60/4000\n",
      "28/28 [==============================] - 10s 350ms/step - loss: 0.9010 - categorical_accuracy: 0.6483\n",
      "Epoch 61/4000\n",
      "28/28 [==============================] - 10s 359ms/step - loss: 0.9495 - categorical_accuracy: 0.6202\n",
      "Epoch 62/4000\n",
      "28/28 [==============================] - 10s 357ms/step - loss: 0.8126 - categorical_accuracy: 0.7056\n",
      "Epoch 63/4000\n",
      "28/28 [==============================] - 10s 345ms/step - loss: 0.7624 - categorical_accuracy: 0.6978\n",
      "Epoch 64/4000\n",
      "28/28 [==============================] - 10s 349ms/step - loss: 0.7810 - categorical_accuracy: 0.6809\n",
      "Epoch 65/4000\n",
      "28/28 [==============================] - 10s 366ms/step - loss: 0.7705 - categorical_accuracy: 0.6888\n",
      "Epoch 66/4000\n",
      "28/28 [==============================] - 10s 364ms/step - loss: 0.7865 - categorical_accuracy: 0.6876\n",
      "Epoch 67/4000\n",
      "28/28 [==============================] - 10s 367ms/step - loss: 0.7961 - categorical_accuracy: 0.6854\n",
      "Epoch 68/4000\n",
      "28/28 [==============================] - 10s 362ms/step - loss: 0.7960 - categorical_accuracy: 0.6798\n",
      "Epoch 69/4000\n",
      "28/28 [==============================] - 10s 356ms/step - loss: 0.7474 - categorical_accuracy: 0.7146\n",
      "Epoch 70/4000\n",
      "28/28 [==============================] - 9s 336ms/step - loss: 0.7505 - categorical_accuracy: 0.7157\n",
      "Epoch 71/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 10s 360ms/step - loss: 0.7501 - categorical_accuracy: 0.6865\n",
      "Epoch 72/4000\n",
      "28/28 [==============================] - 10s 353ms/step - loss: 0.7398 - categorical_accuracy: 0.7225\n",
      "Epoch 73/4000\n",
      "28/28 [==============================] - 10s 354ms/step - loss: 0.6998 - categorical_accuracy: 0.7348\n",
      "Epoch 74/4000\n",
      "28/28 [==============================] - 10s 359ms/step - loss: 0.8101 - categorical_accuracy: 0.6775\n",
      "Epoch 75/4000\n",
      "28/28 [==============================] - 10s 351ms/step - loss: 0.7718 - categorical_accuracy: 0.6876\n",
      "Epoch 76/4000\n",
      "28/28 [==============================] - 10s 348ms/step - loss: 0.7361 - categorical_accuracy: 0.7169\n",
      "Epoch 77/4000\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 0.7720 - categorical_accuracy: 0.6843\n",
      "Epoch 78/4000\n",
      "28/28 [==============================] - 9s 342ms/step - loss: 0.6953 - categorical_accuracy: 0.7157\n",
      "Epoch 79/4000\n",
      "28/28 [==============================] - 9s 324ms/step - loss: 0.8400 - categorical_accuracy: 0.6506\n",
      "Epoch 80/4000\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.7491 - categorical_accuracy: 0.7348\n",
      "Epoch 81/4000\n",
      "28/28 [==============================] - 10s 366ms/step - loss: 0.6749 - categorical_accuracy: 0.7562\n",
      "Epoch 82/4000\n",
      "28/28 [==============================] - 10s 350ms/step - loss: 0.6197 - categorical_accuracy: 0.7742\n",
      "Epoch 83/4000\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.8194 - categorical_accuracy: 0.6978\n",
      "Epoch 84/4000\n",
      "28/28 [==============================] - 9s 335ms/step - loss: 0.7193 - categorical_accuracy: 0.7393\n",
      "Epoch 85/4000\n",
      "28/28 [==============================] - 9s 327ms/step - loss: 0.6617 - categorical_accuracy: 0.7663\n",
      "Epoch 86/4000\n",
      "28/28 [==============================] - 10s 349ms/step - loss: 0.7609 - categorical_accuracy: 0.7169\n",
      "Epoch 87/4000\n",
      "28/28 [==============================] - 9s 337ms/step - loss: 0.6135 - categorical_accuracy: 0.7888\n",
      "Epoch 88/4000\n",
      "28/28 [==============================] - 9s 332ms/step - loss: 0.5782 - categorical_accuracy: 0.8045\n",
      "Epoch 89/4000\n",
      "28/28 [==============================] - 9s 335ms/step - loss: 0.6801 - categorical_accuracy: 0.7843\n",
      "Epoch 90/4000\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6057 - categorical_accuracy: 0.7978\n",
      "Epoch 91/4000\n",
      "28/28 [==============================] - 9s 334ms/step - loss: 0.5650 - categorical_accuracy: 0.8225\n",
      "Epoch 92/4000\n",
      "28/28 [==============================] - 9s 336ms/step - loss: 0.8303 - categorical_accuracy: 0.7652\n",
      "Epoch 93/4000\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.8931 - categorical_accuracy: 0.6719\n",
      "Epoch 94/4000\n",
      "28/28 [==============================] - 9s 316ms/step - loss: 0.7119 - categorical_accuracy: 0.7596\n",
      "Epoch 95/4000\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 0.5888 - categorical_accuracy: 0.8258\n",
      "Epoch 96/4000\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.5671 - categorical_accuracy: 0.8124\n",
      "Epoch 97/4000\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.5685 - categorical_accuracy: 0.8292\n",
      "Epoch 98/4000\n",
      "28/28 [==============================] - 10s 349ms/step - loss: 0.4945 - categorical_accuracy: 0.8270\n",
      "Epoch 99/4000\n",
      "28/28 [==============================] - 10s 327ms/step - loss: 0.4907 - categorical_accuracy: 0.8360\n",
      "Epoch 100/4000\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.5339 - categorical_accuracy: 0.8169\n",
      "Epoch 101/4000\n",
      "28/28 [==============================] - 9s 325ms/step - loss: 0.4423 - categorical_accuracy: 0.8517\n",
      "Epoch 102/4000\n",
      "28/28 [==============================] - 9s 340ms/step - loss: 0.4978 - categorical_accuracy: 0.8393\n",
      "Epoch 103/4000\n",
      "28/28 [==============================] - 10s 337ms/step - loss: 0.5667 - categorical_accuracy: 0.8337\n",
      "Epoch 104/4000\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.4540 - categorical_accuracy: 0.8506\n",
      "Epoch 105/4000\n",
      "28/28 [==============================] - 10s 342ms/step - loss: 0.4064 - categorical_accuracy: 0.8551\n",
      "Epoch 106/4000\n",
      "28/28 [==============================] - 10s 348ms/step - loss: 0.4454 - categorical_accuracy: 0.8506\n",
      "Epoch 107/4000\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 0.5084 - categorical_accuracy: 0.8449\n",
      "Epoch 108/4000\n",
      "28/28 [==============================] - 9s 327ms/step - loss: 0.4326 - categorical_accuracy: 0.8629\n",
      "Epoch 109/4000\n",
      "28/28 [==============================] - 10s 342ms/step - loss: 0.4109 - categorical_accuracy: 0.8618\n",
      "Epoch 110/4000\n",
      "28/28 [==============================] - 9s 341ms/step - loss: 0.4478 - categorical_accuracy: 0.8551\n",
      "Epoch 111/4000\n",
      "28/28 [==============================] - 9s 322ms/step - loss: 0.4958 - categorical_accuracy: 0.8404\n",
      "Epoch 112/4000\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.4293 - categorical_accuracy: 0.8573\n",
      "Epoch 113/4000\n",
      "28/28 [==============================] - 9s 335ms/step - loss: 0.4526 - categorical_accuracy: 0.8596\n",
      "Epoch 114/4000\n",
      "28/28 [==============================] - 9s 323ms/step - loss: 0.3885 - categorical_accuracy: 0.8663\n",
      "Epoch 115/4000\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.4147 - categorical_accuracy: 0.8640\n",
      "Epoch 116/4000\n",
      "28/28 [==============================] - 9s 319ms/step - loss: 0.4063 - categorical_accuracy: 0.8730\n",
      "Epoch 117/4000\n",
      "28/28 [==============================] - 10s 341ms/step - loss: 0.4232 - categorical_accuracy: 0.8438\n",
      "Epoch 118/4000\n",
      "28/28 [==============================] - 9s 333ms/step - loss: 0.3755 - categorical_accuracy: 0.8697\n",
      "Epoch 119/4000\n",
      "28/28 [==============================] - 9s 342ms/step - loss: 0.3755 - categorical_accuracy: 0.8584\n",
      "Epoch 120/4000\n",
      "28/28 [==============================] - 10s 341ms/step - loss: 0.3427 - categorical_accuracy: 0.8820\n",
      "Epoch 121/4000\n",
      "28/28 [==============================] - 9s 322ms/step - loss: 0.3461 - categorical_accuracy: 0.8787\n",
      "Epoch 122/4000\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.5643 - categorical_accuracy: 0.8191\n",
      "Epoch 123/4000\n",
      "28/28 [==============================] - 9s 335ms/step - loss: 0.4758 - categorical_accuracy: 0.8483\n",
      "Epoch 124/4000\n",
      "28/28 [==============================] - 10s 343ms/step - loss: 0.5291 - categorical_accuracy: 0.8225\n",
      "Epoch 125/4000\n",
      "28/28 [==============================] - 10s 342ms/step - loss: 0.3628 - categorical_accuracy: 0.8730\n",
      "Epoch 126/4000\n",
      "28/28 [==============================] - 10s 341ms/step - loss: 0.3531 - categorical_accuracy: 0.8719\n",
      "Epoch 127/4000\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.3463 - categorical_accuracy: 0.8753\n",
      "Epoch 128/4000\n",
      "28/28 [==============================] - 9s 323ms/step - loss: 0.4096 - categorical_accuracy: 0.8562\n",
      "Epoch 129/4000\n",
      "28/28 [==============================] - 9s 342ms/step - loss: 0.3257 - categorical_accuracy: 0.8888\n",
      "Epoch 130/4000\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.3774 - categorical_accuracy: 0.8607\n",
      "Epoch 131/4000\n",
      "28/28 [==============================] - 10s 360ms/step - loss: 0.4182 - categorical_accuracy: 0.8562\n",
      "Epoch 132/4000\n",
      "28/28 [==============================] - 10s 357ms/step - loss: 0.3483 - categorical_accuracy: 0.8798\n",
      "Epoch 133/4000\n",
      "28/28 [==============================] - 9s 336ms/step - loss: 0.3739 - categorical_accuracy: 0.8730\n",
      "Epoch 134/4000\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.2709 - categorical_accuracy: 0.8955\n",
      "Epoch 135/4000\n",
      "28/28 [==============================] - 9s 311ms/step - loss: 0.3364 - categorical_accuracy: 0.8843\n",
      "Epoch 136/4000\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.3089 - categorical_accuracy: 0.8910\n",
      "Epoch 137/4000\n",
      "28/28 [==============================] - 9s 332ms/step - loss: 0.3252 - categorical_accuracy: 0.8966\n",
      "Epoch 138/4000\n",
      "28/28 [==============================] - 9s 321ms/step - loss: 0.3375 - categorical_accuracy: 0.8809\n",
      "Epoch 139/4000\n",
      "28/28 [==============================] - 10s 354ms/step - loss: 0.3086 - categorical_accuracy: 0.8831\n",
      "Epoch 140/4000\n",
      "28/28 [==============================] - 10s 358ms/step - loss: 0.3785 - categorical_accuracy: 0.8730\n",
      "Epoch 141/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 10s 356ms/step - loss: 0.4466 - categorical_accuracy: 0.8494\n",
      "Epoch 142/4000\n",
      "28/28 [==============================] - 10s 361ms/step - loss: 0.3404 - categorical_accuracy: 0.8876\n",
      "Epoch 143/4000\n",
      "28/28 [==============================] - 9s 325ms/step - loss: 0.3237 - categorical_accuracy: 0.8865\n",
      "Epoch 144/4000\n",
      "28/28 [==============================] - 10s 349ms/step - loss: 0.4863 - categorical_accuracy: 0.8674\n",
      "Epoch 145/4000\n",
      "28/28 [==============================] - 10s 359ms/step - loss: 0.3731 - categorical_accuracy: 0.8730\n",
      "Epoch 146/4000\n",
      "28/28 [==============================] - 10s 360ms/step - loss: 0.3025 - categorical_accuracy: 0.9034\n",
      "Epoch 147/4000\n",
      "28/28 [==============================] - 10s 349ms/step - loss: 0.2973 - categorical_accuracy: 0.8944\n",
      "Epoch 148/4000\n",
      "28/28 [==============================] - 9s 323ms/step - loss: 0.3183 - categorical_accuracy: 0.9000\n",
      "Epoch 149/4000\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.3835 - categorical_accuracy: 0.8607\n",
      "Epoch 150/4000\n",
      "28/28 [==============================] - 9s 318ms/step - loss: 0.4287 - categorical_accuracy: 0.8607\n",
      "Epoch 151/4000\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.3893 - categorical_accuracy: 0.8753\n",
      "Epoch 152/4000\n",
      "28/28 [==============================] - 10s 353ms/step - loss: 0.3097 - categorical_accuracy: 0.8944\n",
      "Epoch 153/4000\n",
      "28/28 [==============================] - 10s 350ms/step - loss: 0.3253 - categorical_accuracy: 0.8933\n",
      "Epoch 154/4000\n",
      "28/28 [==============================] - 9s 341ms/step - loss: 0.2852 - categorical_accuracy: 0.9146\n",
      "Epoch 155/4000\n",
      "28/28 [==============================] - 9s 318ms/step - loss: 0.4103 - categorical_accuracy: 0.8663\n",
      "Epoch 156/4000\n",
      "28/28 [==============================] - 10s 349ms/step - loss: 0.2870 - categorical_accuracy: 0.9101\n",
      "Epoch 157/4000\n",
      "28/28 [==============================] - 10s 352ms/step - loss: 0.2631 - categorical_accuracy: 0.9180\n",
      "Epoch 158/4000\n",
      "28/28 [==============================] - 10s 360ms/step - loss: 0.2468 - categorical_accuracy: 0.9191\n",
      "Epoch 159/4000\n",
      "28/28 [==============================] - 10s 354ms/step - loss: 0.3287 - categorical_accuracy: 0.9045\n",
      "Epoch 160/4000\n",
      "28/28 [==============================] - 10s 355ms/step - loss: 0.3261 - categorical_accuracy: 0.9022\n",
      "Epoch 161/4000\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.3276 - categorical_accuracy: 0.9022\n",
      "Epoch 162/4000\n",
      "28/28 [==============================] - 10s 354ms/step - loss: 0.3157 - categorical_accuracy: 0.8910\n",
      "Epoch 163/4000\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.4964 - categorical_accuracy: 0.8326\n",
      "Epoch 164/4000\n",
      "28/28 [==============================] - 10s 358ms/step - loss: 0.3191 - categorical_accuracy: 0.9067\n",
      "Epoch 165/4000\n",
      "28/28 [==============================] - 10s 343ms/step - loss: 0.3328 - categorical_accuracy: 0.8966\n",
      "Epoch 166/4000\n",
      "28/28 [==============================] - 10s 339ms/step - loss: 0.2664 - categorical_accuracy: 0.9191\n",
      "Epoch 167/4000\n",
      "28/28 [==============================] - 10s 356ms/step - loss: 0.2281 - categorical_accuracy: 0.9225\n",
      "Epoch 168/4000\n",
      "28/28 [==============================] - 10s 322ms/step - loss: 0.2872 - categorical_accuracy: 0.9191\n",
      "Epoch 169/4000\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.3235 - categorical_accuracy: 0.9090\n",
      "Epoch 170/4000\n",
      "28/28 [==============================] - 9s 341ms/step - loss: 0.2714 - categorical_accuracy: 0.9112\n",
      "Epoch 171/4000\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.3545 - categorical_accuracy: 0.8865\n",
      "Epoch 172/4000\n",
      "28/28 [==============================] - 10s 362ms/step - loss: 0.3791 - categorical_accuracy: 0.8775\n",
      "Epoch 173/4000\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 0.3390 - categorical_accuracy: 0.8798\n",
      "Epoch 174/4000\n",
      "28/28 [==============================] - 10s 355ms/step - loss: 0.2956 - categorical_accuracy: 0.9056\n",
      "Epoch 175/4000\n",
      "28/28 [==============================] - 10s 351ms/step - loss: 0.2409 - categorical_accuracy: 0.9112\n",
      "Epoch 176/4000\n",
      "28/28 [==============================] - 10s 356ms/step - loss: 0.2438 - categorical_accuracy: 0.9157\n",
      "Epoch 177/4000\n",
      "28/28 [==============================] - 10s 357ms/step - loss: 0.2600 - categorical_accuracy: 0.9124\n",
      "Epoch 178/4000\n",
      "28/28 [==============================] - 10s 363ms/step - loss: 0.2523 - categorical_accuracy: 0.9225\n",
      "Epoch 179/4000\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 0.3030 - categorical_accuracy: 0.8933\n",
      "Epoch 180/4000\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.2418 - categorical_accuracy: 0.9202\n",
      "Epoch 181/4000\n",
      "28/28 [==============================] - 10s 356ms/step - loss: 0.2248 - categorical_accuracy: 0.9247\n",
      "Epoch 182/4000\n",
      "28/28 [==============================] - 10s 349ms/step - loss: 0.2143 - categorical_accuracy: 0.9371\n",
      "Epoch 183/4000\n",
      "28/28 [==============================] - 8s 299ms/step - loss: 0.2265 - categorical_accuracy: 0.9247\n",
      "Epoch 184/4000\n",
      "28/28 [==============================] - 7s 243ms/step - loss: 0.2863 - categorical_accuracy: 0.9056\n",
      "Epoch 185/4000\n",
      "28/28 [==============================] - 7s 247ms/step - loss: 0.2577 - categorical_accuracy: 0.9135\n",
      "Epoch 186/4000\n",
      "28/28 [==============================] - 7s 229ms/step - loss: 0.2632 - categorical_accuracy: 0.9146\n",
      "Epoch 187/4000\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.2652 - categorical_accuracy: 0.9056\n",
      "Epoch 188/4000\n",
      "28/28 [==============================] - 7s 261ms/step - loss: 0.2212 - categorical_accuracy: 0.9258\n",
      "Epoch 189/4000\n",
      "28/28 [==============================] - 7s 243ms/step - loss: 0.2000 - categorical_accuracy: 0.9360\n",
      "Epoch 190/4000\n",
      "28/28 [==============================] - 7s 242ms/step - loss: 0.1685 - categorical_accuracy: 0.9461\n",
      "Epoch 191/4000\n",
      "28/28 [==============================] - 7s 257ms/step - loss: 0.1777 - categorical_accuracy: 0.9393\n",
      "Epoch 192/4000\n",
      "28/28 [==============================] - 7s 259ms/step - loss: 0.2916 - categorical_accuracy: 0.9281\n",
      "Epoch 193/4000\n",
      "28/28 [==============================] - 7s 261ms/step - loss: 0.4422 - categorical_accuracy: 0.8506\n",
      "Epoch 194/4000\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 0.3183 - categorical_accuracy: 0.8876\n",
      "Epoch 195/4000\n",
      "28/28 [==============================] - 7s 251ms/step - loss: 0.4170 - categorical_accuracy: 0.8674\n",
      "Epoch 196/4000\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 0.2542 - categorical_accuracy: 0.9067\n",
      "Epoch 197/4000\n",
      "28/28 [==============================] - 7s 257ms/step - loss: 0.2188 - categorical_accuracy: 0.9247\n",
      "Epoch 198/4000\n",
      "28/28 [==============================] - 7s 238ms/step - loss: 0.2523 - categorical_accuracy: 0.9112\n",
      "Epoch 199/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.1972 - categorical_accuracy: 0.9371\n",
      "Epoch 200/4000\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 0.1819 - categorical_accuracy: 0.9348\n",
      "Epoch 201/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.2655 - categorical_accuracy: 0.9135\n",
      "Epoch 202/4000\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 0.2435 - categorical_accuracy: 0.9225\n",
      "Epoch 203/4000\n",
      "28/28 [==============================] - 7s 247ms/step - loss: 0.2380 - categorical_accuracy: 0.9191\n",
      "Epoch 204/4000\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.1840 - categorical_accuracy: 0.9416\n",
      "Epoch 205/4000\n",
      "28/28 [==============================] - 7s 253ms/step - loss: 0.2429 - categorical_accuracy: 0.9315\n",
      "Epoch 206/4000\n",
      "28/28 [==============================] - 7s 246ms/step - loss: 0.2266 - categorical_accuracy: 0.9281\n",
      "Epoch 207/4000\n",
      "28/28 [==============================] - 7s 260ms/step - loss: 0.2723 - categorical_accuracy: 0.9124\n",
      "Epoch 208/4000\n",
      "28/28 [==============================] - 7s 255ms/step - loss: 0.1958 - categorical_accuracy: 0.9337\n",
      "Epoch 209/4000\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.1606 - categorical_accuracy: 0.9494\n",
      "Epoch 210/4000\n",
      "28/28 [==============================] - 7s 253ms/step - loss: 0.3497 - categorical_accuracy: 0.8933\n",
      "Epoch 211/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 7s 237ms/step - loss: 0.2730 - categorical_accuracy: 0.9056\n",
      "Epoch 212/4000\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.2420 - categorical_accuracy: 0.9180\n",
      "Epoch 213/4000\n",
      "28/28 [==============================] - 6s 233ms/step - loss: 0.1926 - categorical_accuracy: 0.9281\n",
      "Epoch 214/4000\n",
      "28/28 [==============================] - 7s 241ms/step - loss: 0.1684 - categorical_accuracy: 0.9472\n",
      "Epoch 215/4000\n",
      "28/28 [==============================] - 7s 253ms/step - loss: 0.1996 - categorical_accuracy: 0.9393\n",
      "Epoch 216/4000\n",
      "28/28 [==============================] - 7s 255ms/step - loss: 0.3089 - categorical_accuracy: 0.9101\n",
      "Epoch 217/4000\n",
      "28/28 [==============================] - 7s 246ms/step - loss: 0.2990 - categorical_accuracy: 0.8989\n",
      "Epoch 218/4000\n",
      "28/28 [==============================] - 7s 249ms/step - loss: 0.2106 - categorical_accuracy: 0.9303\n",
      "Epoch 219/4000\n",
      "28/28 [==============================] - 7s 250ms/step - loss: 0.2031 - categorical_accuracy: 0.9326\n",
      "Epoch 220/4000\n",
      "28/28 [==============================] - 7s 253ms/step - loss: 0.2143 - categorical_accuracy: 0.9393\n",
      "Epoch 221/4000\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 0.1705 - categorical_accuracy: 0.9404\n",
      "Epoch 222/4000\n",
      "28/28 [==============================] - 7s 255ms/step - loss: 0.1398 - categorical_accuracy: 0.9573\n",
      "Epoch 223/4000\n",
      "28/28 [==============================] - 7s 245ms/step - loss: 0.1448 - categorical_accuracy: 0.9551\n",
      "Epoch 224/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.1777 - categorical_accuracy: 0.9371\n",
      "Epoch 225/4000\n",
      "28/28 [==============================] - 7s 250ms/step - loss: 0.1336 - categorical_accuracy: 0.9539\n",
      "Epoch 226/4000\n",
      "28/28 [==============================] - 7s 242ms/step - loss: 0.1256 - categorical_accuracy: 0.9607\n",
      "Epoch 227/4000\n",
      "28/28 [==============================] - 7s 259ms/step - loss: 0.1272 - categorical_accuracy: 0.9618\n",
      "Epoch 228/4000\n",
      "28/28 [==============================] - 8s 282ms/step - loss: 0.2790 - categorical_accuracy: 0.9101\n",
      "Epoch 229/4000\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.2312 - categorical_accuracy: 0.9270\n",
      "Epoch 230/4000\n",
      "28/28 [==============================] - 7s 241ms/step - loss: 0.2174 - categorical_accuracy: 0.9315\n",
      "Epoch 231/4000\n",
      "28/28 [==============================] - 7s 226ms/step - loss: 0.3466 - categorical_accuracy: 0.9011\n",
      "Epoch 232/4000\n",
      "28/28 [==============================] - 7s 249ms/step - loss: 0.2395 - categorical_accuracy: 0.9180\n",
      "Epoch 233/4000\n",
      "28/28 [==============================] - 7s 264ms/step - loss: 0.1424 - categorical_accuracy: 0.9573\n",
      "Epoch 234/4000\n",
      "28/28 [==============================] - 7s 234ms/step - loss: 0.1362 - categorical_accuracy: 0.9584\n",
      "Epoch 235/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.2270 - categorical_accuracy: 0.9360\n",
      "Epoch 236/4000\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 0.2784 - categorical_accuracy: 0.9146\n",
      "Epoch 237/4000\n",
      "28/28 [==============================] - 7s 245ms/step - loss: 0.1787 - categorical_accuracy: 0.9483\n",
      "Epoch 238/4000\n",
      "28/28 [==============================] - 7s 257ms/step - loss: 0.2401 - categorical_accuracy: 0.9337\n",
      "Epoch 239/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.1490 - categorical_accuracy: 0.9494\n",
      "Epoch 240/4000\n",
      "28/28 [==============================] - 7s 244ms/step - loss: 0.1455 - categorical_accuracy: 0.9472\n",
      "Epoch 241/4000\n",
      "28/28 [==============================] - 7s 264ms/step - loss: 0.1662 - categorical_accuracy: 0.9517\n",
      "Epoch 242/4000\n",
      "28/28 [==============================] - 7s 243ms/step - loss: 0.1473 - categorical_accuracy: 0.9573\n",
      "Epoch 243/4000\n",
      "28/28 [==============================] - 7s 245ms/step - loss: 0.1395 - categorical_accuracy: 0.9562\n",
      "Epoch 244/4000\n",
      "28/28 [==============================] - 7s 249ms/step - loss: 0.1947 - categorical_accuracy: 0.9438\n",
      "Epoch 245/4000\n",
      "28/28 [==============================] - 7s 252ms/step - loss: 0.1464 - categorical_accuracy: 0.9584\n",
      "Epoch 246/4000\n",
      "28/28 [==============================] - 7s 255ms/step - loss: 0.1297 - categorical_accuracy: 0.9584\n",
      "Epoch 247/4000\n",
      "28/28 [==============================] - 7s 253ms/step - loss: 0.1255 - categorical_accuracy: 0.9640\n",
      "Epoch 248/4000\n",
      "28/28 [==============================] - 7s 238ms/step - loss: 0.1569 - categorical_accuracy: 0.9472\n",
      "Epoch 249/4000\n",
      "28/28 [==============================] - 7s 244ms/step - loss: 0.1285 - categorical_accuracy: 0.9562\n",
      "Epoch 250/4000\n",
      "28/28 [==============================] - 7s 266ms/step - loss: 0.1174 - categorical_accuracy: 0.9674\n",
      "Epoch 251/4000\n",
      "28/28 [==============================] - 7s 260ms/step - loss: 0.1203 - categorical_accuracy: 0.9596\n",
      "Epoch 252/4000\n",
      "28/28 [==============================] - 7s 264ms/step - loss: 0.1265 - categorical_accuracy: 0.9573\n",
      "Epoch 253/4000\n",
      "28/28 [==============================] - 8s 275ms/step - loss: 0.1431 - categorical_accuracy: 0.9472\n",
      "Epoch 254/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.1249 - categorical_accuracy: 0.9562\n",
      "Epoch 255/4000\n",
      "28/28 [==============================] - 7s 240ms/step - loss: 0.1106 - categorical_accuracy: 0.9629\n",
      "Epoch 256/4000\n",
      "28/28 [==============================] - 7s 242ms/step - loss: 0.1569 - categorical_accuracy: 0.9562\n",
      "Epoch 257/4000\n",
      "28/28 [==============================] - 7s 247ms/step - loss: 0.2533 - categorical_accuracy: 0.9225\n",
      "Epoch 258/4000\n",
      "28/28 [==============================] - 8s 274ms/step - loss: 0.1330 - categorical_accuracy: 0.9607\n",
      "Epoch 259/4000\n",
      "28/28 [==============================] - 7s 264ms/step - loss: 0.1502 - categorical_accuracy: 0.9528\n",
      "Epoch 260/4000\n",
      "28/28 [==============================] - 7s 240ms/step - loss: 0.3821 - categorical_accuracy: 0.9101\n",
      "Epoch 261/4000\n",
      "28/28 [==============================] - 7s 265ms/step - loss: 0.1799 - categorical_accuracy: 0.9506\n",
      "Epoch 262/4000\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 0.1634 - categorical_accuracy: 0.9539\n",
      "Epoch 263/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.3077 - categorical_accuracy: 0.9270\n",
      "Epoch 264/4000\n",
      "28/28 [==============================] - 7s 263ms/step - loss: 0.1547 - categorical_accuracy: 0.9607\n",
      "Epoch 265/4000\n",
      "28/28 [==============================] - 7s 253ms/step - loss: 0.2201 - categorical_accuracy: 0.9427\n",
      "Epoch 266/4000\n",
      "28/28 [==============================] - 7s 249ms/step - loss: 0.1806 - categorical_accuracy: 0.9494\n",
      "Epoch 267/4000\n",
      "28/28 [==============================] - 7s 247ms/step - loss: 0.1827 - categorical_accuracy: 0.9438\n",
      "Epoch 268/4000\n",
      "28/28 [==============================] - 7s 239ms/step - loss: 0.1349 - categorical_accuracy: 0.9640\n",
      "Epoch 269/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.1299 - categorical_accuracy: 0.9596\n",
      "Epoch 270/4000\n",
      "28/28 [==============================] - 7s 235ms/step - loss: 0.1392 - categorical_accuracy: 0.9573\n",
      "Epoch 271/4000\n",
      "28/28 [==============================] - 7s 241ms/step - loss: 0.1509 - categorical_accuracy: 0.9596\n",
      "Epoch 272/4000\n",
      "28/28 [==============================] - 7s 238ms/step - loss: 0.1787 - categorical_accuracy: 0.9607\n",
      "Epoch 273/4000\n",
      "28/28 [==============================] - 7s 262ms/step - loss: 0.1088 - categorical_accuracy: 0.9607\n",
      "Epoch 274/4000\n",
      "28/28 [==============================] - 7s 260ms/step - loss: 0.1120 - categorical_accuracy: 0.9652\n",
      "Epoch 275/4000\n",
      "28/28 [==============================] - 7s 267ms/step - loss: 0.2323 - categorical_accuracy: 0.9427\n",
      "Epoch 276/4000\n",
      "28/28 [==============================] - 8s 266ms/step - loss: 0.1856 - categorical_accuracy: 0.9461\n",
      "Epoch 277/4000\n",
      "28/28 [==============================] - 8s 287ms/step - loss: 0.1274 - categorical_accuracy: 0.9584\n",
      "Epoch 278/4000\n",
      "28/28 [==============================] - 8s 289ms/step - loss: 0.1591 - categorical_accuracy: 0.9629\n",
      "Epoch 279/4000\n",
      "28/28 [==============================] - 8s 272ms/step - loss: 0.1678 - categorical_accuracy: 0.9461\n",
      "Epoch 280/4000\n",
      "28/28 [==============================] - 7s 237ms/step - loss: 0.1444 - categorical_accuracy: 0.9539\n",
      "Epoch 281/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 7s 243ms/step - loss: 0.2480 - categorical_accuracy: 0.9449\n",
      "Epoch 282/4000\n",
      "28/28 [==============================] - 7s 243ms/step - loss: 0.5146 - categorical_accuracy: 0.8483\n",
      "Epoch 283/4000\n",
      "28/28 [==============================] - 7s 252ms/step - loss: 0.7911 - categorical_accuracy: 0.7573\n",
      "Epoch 284/4000\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.2695 - categorical_accuracy: 0.9292\n",
      "Epoch 285/4000\n",
      "28/28 [==============================] - 7s 238ms/step - loss: 0.2473 - categorical_accuracy: 0.9393\n",
      "Epoch 286/4000\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.1964 - categorical_accuracy: 0.9416\n",
      "Epoch 287/4000\n",
      "28/28 [==============================] - 7s 252ms/step - loss: 0.2259 - categorical_accuracy: 0.9371\n",
      "Epoch 288/4000\n",
      "28/28 [==============================] - 7s 246ms/step - loss: 0.2197 - categorical_accuracy: 0.9438\n",
      "Epoch 289/4000\n",
      "28/28 [==============================] - 7s 238ms/step - loss: 0.1592 - categorical_accuracy: 0.9483\n",
      "Epoch 290/4000\n",
      "28/28 [==============================] - 7s 252ms/step - loss: 0.1442 - categorical_accuracy: 0.9539\n",
      "Epoch 291/4000\n",
      "28/28 [==============================] - 7s 253ms/step - loss: 0.1384 - categorical_accuracy: 0.9652\n",
      "Epoch 292/4000\n",
      "28/28 [==============================] - 7s 247ms/step - loss: 0.1540 - categorical_accuracy: 0.9539\n",
      "Epoch 293/4000\n",
      "28/28 [==============================] - 7s 247ms/step - loss: 0.1437 - categorical_accuracy: 0.9517\n",
      "Epoch 294/4000\n",
      "28/28 [==============================] - 7s 233ms/step - loss: 0.2640 - categorical_accuracy: 0.9236\n",
      "Epoch 295/4000\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.2398 - categorical_accuracy: 0.9292\n",
      "Epoch 296/4000\n",
      "28/28 [==============================] - 7s 250ms/step - loss: 0.1716 - categorical_accuracy: 0.9416\n",
      "Epoch 297/4000\n",
      "28/28 [==============================] - 7s 234ms/step - loss: 0.1505 - categorical_accuracy: 0.9528\n",
      "Epoch 298/4000\n",
      "28/28 [==============================] - 7s 253ms/step - loss: 0.1700 - categorical_accuracy: 0.9584\n",
      "Epoch 299/4000\n",
      "28/28 [==============================] - 7s 250ms/step - loss: 0.1219 - categorical_accuracy: 0.9584\n",
      "Epoch 300/4000\n",
      "28/28 [==============================] - 7s 255ms/step - loss: 0.1280 - categorical_accuracy: 0.9607\n",
      "Epoch 301/4000\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.1035 - categorical_accuracy: 0.9584\n",
      "Epoch 302/4000\n",
      "28/28 [==============================] - 7s 259ms/step - loss: 0.1529 - categorical_accuracy: 0.9506\n",
      "Epoch 303/4000\n",
      "28/28 [==============================] - 7s 255ms/step - loss: 0.1446 - categorical_accuracy: 0.9629\n",
      "Epoch 304/4000\n",
      "28/28 [==============================] - 7s 255ms/step - loss: 0.1315 - categorical_accuracy: 0.9596\n",
      "Epoch 305/4000\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.1610 - categorical_accuracy: 0.9528\n",
      "Epoch 306/4000\n",
      "28/28 [==============================] - 7s 250ms/step - loss: 0.0879 - categorical_accuracy: 0.9742\n",
      "\n",
      "Reached 97.00% accuracy, so stopping training!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x279264d3988>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callb = myCallback()\n",
    "\n",
    "#training the model\n",
    "model.fit(X_train, y_train, epochs = 4000, callbacks = callb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0adbaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[94,  5],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[87, 12],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[89, 10],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[96,  3],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [30, 69]]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using confusion matrix to determine how well the model performs on the test set (false positive and negatives)\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis = 1).tolist()\n",
    "yhat = np.argmax(yhat, axis = 1).tolist()\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1970e771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696969696969697"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing out the accuracy\n",
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a2bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the weights\n",
    "model.save('model_weights\\\\5_actions_696(to_test).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d06b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the weights of a previously saved model\n",
    "model.load_weights('model_weights\\\\5_actions_741(to_test).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "678ee10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "head_hit\n",
      "head_scratch\n",
      "head_hit\n",
      "head_hit\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "no_action\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "no_action\n",
      "no_action\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "no_action\n",
      "no_action\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "head_scratch\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "head_hit\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "hand_flap\n",
      "cover_face\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "no_action\n",
      "no_action\n",
      "hand_bite\n",
      "no_action\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "hand_bite\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "head_scratch\n",
      "cover_ears\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "cover_ears\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "head_scratch\n",
      "cover_ears\n",
      "cover_ears\n",
      "head_hit\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n",
      "no_action\n"
     ]
    }
   ],
   "source": [
    "#testing in real-time\n",
    "\n",
    "colors = [(0,0,0), (255,255,255), (0,255,0), (255,0,0), (0,0,255), (125, 125, 125), (125, 0, 200)]\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = [0]\n",
    "threshold = 0.95\n",
    "\n",
    "#choosing the camera to use\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#drawing specs for face dots\n",
    "drawing_spec_circle = mp_drawing.DrawingSpec()\n",
    "drawing_spec_circle.circle_radius = 1\n",
    "drawing_spec_circle.thickness = 1\n",
    "drawing_spec_circle.color = (0,0,255)\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "#drawing specs for face connections\n",
    "drawing_spec_line = mp_drawing.DrawingSpec()\n",
    "drawing_spec_line.thickness = 1\n",
    "\n",
    "#starting the loop\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.8) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        #count and show fps\n",
    "        new_frame_time = time.time()\n",
    "        fps = 1/(new_frame_time-prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "        fps = int(fps)\n",
    "        fps = str(fps)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(image, fps, (550, 120), font, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "        \n",
    "        #drawing landmarks\n",
    "        draw_landmarks(image, results, drawing_spec_circle, drawing_spec_line)\n",
    "        \n",
    "        #extracting keypoints and feeding them to the LSTM for prediction\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-10:]\n",
    "        \n",
    "        if len(sequence) == 10:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            image = visualize_probabilities(res, actions, image, colors)\n",
    "        \n",
    "        #this would be the rendering logic if one would want to write the action. The first line implies that the action gets\n",
    "        #written only if predicted for 10 consecutive frames, to give an higher stability to the model. This logic is not used\n",
    "        #now, if one would like to implement that, just add 2 lines of code to display a text box with the sentence in\n",
    "            if np.unique(predictions[-10:])[0] == np.argmax(res):\n",
    "                if res[np.argmax(res)] > threshold:\n",
    "                    if len(sentence) > 0:\n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])    \n",
    "\n",
    "            if len(sentence) > 5:\n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "        #showing image with predictions\n",
    "        cv2.imshow('the feed', image)\n",
    "\n",
    "        #close loop\n",
    "        if cv2.waitKey(10) & 0XFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47127079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
